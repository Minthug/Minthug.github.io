# Sniff & Steps 프로젝트 예상 질문:

Docker를 선택한 이유는?
AWS ECS, Lambda 같은 서비스를 사용하기에는 충분히 학습되지 않았고
여러개의 EC2 인스턴스를 띄우기에는 비용적인 부담이 컸습니다.
이에 도커를 사용하여 하나의 EC2에서 웹서버, 데이터베이스, 애플리케이션을 컨테이로 분리 실행하여
환경 통일과 Docker compose up을 사용해 배포 간소화를 얻었습니다.
또한 해당 프로젝트를 하며 Docker에 대한 학습과 경험을 쌓는 좋은 프로젝트였습니다.


멀티 스테이지 빌드를 어떻게 구현했나요?
스니프 스텝은 싱글 스테이지로 구성되어 있습니다.
멀티 스테이지 빌드를 적용하면 이미지를 30~50% 줄일수 있습니다
빌드 환경과 실행 환경을 분리해서 최종 이미지에는 JAR 파일과 JRE만 포함시키는 방식으로 최적화할 계획입니다.


Docker 네트워크와 볼륨 관리는 어떻게 했나요?

Nginx를 리버스 프록시로 사용한 이유는?
복잡한 포트 관리를 단순화하고 사용자 요청을 받아서 Nginx가 적절히 프론트엔드와 백엔드로 연결해주기에 
추후 확장시 백엔드 인스턴스로 요청 분산도 가능하여 확장성까지 생각하기에 좋았습니다.


리소스 최적화는 구체적으로 어떻게 했나요?

S3 업로드 관련:
서버를 통한 업로드 방식을 선택한 이유는?
S3 접근 키를 클라이언트에게 노출하지 않아도 되고 서버에서 파일을 직접 검증하고 처리할 수 있어서 악성 파일 업로드를 방지하는 측면에서
보안까지 신경쓸수 있다는 점도 있었습니다.

또한 수정이 필요할때 서버 코드만 수정하기만 하면 되서 유지보수도 용이한 점도 있습니다.

200ms 성능 차이보다 보안을 우선시한 이유는?
S3 직접 업로드보다 200ms 정도 느리지만, 보안성을 최우선으로 고려해서 서버 경유 방식으로 선택했습니다.

대용량 파일 업로드 시 서버 부하는 어떻게 해결했나요?
비동기처리로 여러 파일을 순차적으로 업로드하는 것이 아닌 병렬로 동시 업로드하게 만들고
파일을 메모리에 전체 업로드하지 않고 스트림으로 처리해서 메모리 사용량을 최소화 했습니다.
또한 개별 파일 업로드 실패 시에도 전체 프로세스가 중단되지 않도록 예외 처리를 했습니다.

비동기 처리는 어떻게 구현했나요?
Spring Async와 CompletableFuture 를 활용했습니다.


# GateStatus 프로젝트 예상 질문:
아키텍처 설계:

멀티 데이터베이스 전략을 선택한 이유는?
프로젝트 특성상 데이터 별로 분리하는 전략이 좋다고 생각했습니다.
Postgre로 국회의원 기본정보, 투표 기록 등 정확한 관계와 트랜잭션이 중요한 내용
MongoDB로 발언내용, AI 분석 키워드 등 유연한 스키마가 필요한 AI 분석 결과
Redis로 빠른 조회가 필요한 실시간 데이터용으로 각 데이터베이스의 장점을 최대화해서 조회 성능 70% 향상을 달성했습니다.


PostgreSQL, MongoDB, Redis를 각각 어떤 용도로 사용했나요?

도메인별 모듈 분리는 어떻게 설계했나요?

성능 최적화:

N+1 쿼리 문제를 어떻게 발견하고 해결했나요?
캐싱 전략에서 Redis와 Caffeine을 함께 사용한 이유는?
대량 데이터 동기화에서 메모리 문제를 어떻게 해결했나요?
배치 처리 크기를 10개로 정한 기준은?

AI 연동:

OpenAI API 사용 시 비용은 어떻게 관리했나요?
AI 분석 결과의 정확도는 어떻게 검증했나요?

트러블슈팅:

15분에서 2분으로 단축한 구체적인 방법은?
트랜잭션 분리 시 데이터 일관성은 어떻게 보장했나요?